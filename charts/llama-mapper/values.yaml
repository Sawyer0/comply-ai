# Default values for llama-mapper Helm chart.
# These can be overridden via --set or -f custom-values.yaml

image:
  repository: ghcr.io/your-org/llama-mapper
  tag: "0.1.0"
  pullPolicy: IfNotPresent

replicaCount: 1

profile: tgi # one of: tgi (CPU), vllm (GPU)

service:
  type: ClusterIP
  port: 8000
  annotations: {}

# HTTP path probes
probes:
  enabled: true
  path: /health
  initialDelaySeconds: 10
  periodSeconds: 15
  timeoutSeconds: 3
  failureThreshold: 3

resources:
  # Default CPU profile (TGI remote backend)
  tgi:
    requests:
      cpu: "250m"
      memory: "512Mi"
    limits:
      cpu: "1"
      memory: "1Gi"
  # GPU profile (vLLM in-process)
  vllm:
    requests:
      cpu: "2"
      memory: "8Gi"
      nvidia.com/gpu: 1
    limits:
      cpu: "4"
      memory: "16Gi"
      nvidia.com/gpu: 1

nodeSelector: {}
# Example for GPU nodes:
# nodeSelector:
#   nvidia.com/gpu.present: "true"

tolerations: []
# - key: "nvidia.com/gpu"
#   operator: "Exists"
#   effect: "NoSchedule"

# Mapper tunables (contract/SLO enforcement)
mapper:
  timeoutMs: 500
  maxPayloadKb: 64
  rejectOnRawContent: true

podAnnotations: {}

podSecurityContext:
  runAsNonRoot: true
  runAsUser: 10001

securityContext:
  allowPrivilegeEscalation: false
  readOnlyRootFilesystem: false
  capabilities:
    drop:
      - ALL

autoscaling:
  enabled: true
  minReplicas: 1
  maxReplicas: 5
  targetCPUUtilizationPercentage: 70

# Environment variables for the application
env:
  - name: LLAMA_MAPPER_SERVING__HOST
    value: "0.0.0.0"
  - name: LLAMA_MAPPER_SERVING__PORT
    value: "8000"
  - name: LLAMA_MAPPER_SERVING__BACKEND
    valueFromProfile: true # when true, set value to profile (tgi or vllm)
  - name: LLAMA_MAPPER_SERVING__MAPPER_TIMEOUT_MS
    value: "{{ .Values.mapper.timeoutMs }}"
  - name: LLAMA_MAPPER_SERVING__MAX_PAYLOAD_KB
    value: "{{ .Values.mapper.maxPayloadKb }}"
  - name: LLAMA_MAPPER_SERVING__REJECT_ON_RAW_CONTENT
    value: "{{ .Values.mapper.rejectOnRawContent }}"
  - name: LLAMA_MAPPER_MODEL__QUANTIZATION
    value: "" # optional: 8bit or 4bit (training/inference loaders)
  - name: LLAMA_MAPPER_TAXONOMY_PATH
    value: "/app/pillars-detectors/taxonomy.yaml"
  - name: LLAMA_MAPPER_FRAMEWORKS_PATH
    value: "/app/pillars-detectors/frameworks.yaml"
  - name: LLAMA_MAPPER_DETECTORS_PATH
    value: "/app/pillars-detectors"

# External config map names containing the detector taxonomy/framework/schema
# If provided, they will be mounted into /app/pillars-detectors
externalConfigMaps:
  enabled: false
  names: []
  # - pillars-detectors-taxonomy
  # - pillars-detectors-frameworks
  # - pillars-detectors-mappings

# Optionally create ConfigMaps from inline content in values (for small demos)
inlineConfigs:
  enabled: false
  taxonomyYaml: ""
  frameworksYaml: ""
  schemaJson: ""
  # detectors is a dictionary of filename: content
  detectors: {}

serviceAccount:
  create: true
  name: ""

ingress:
  enabled: false
  className: ""
  annotations: {}
  hosts:
    - host: llama-mapper.local
      paths:
        - path: /
          pathType: Prefix
  tls: []

# Backup and restore configuration
backups:
  enabled: false
  s3:
    bucket: ""
    prefix: "backups/llama-mapper"
    region: "us-east-1"
    # Optionally reference AWS credentials via Kubernetes Secret
    awsAccessKeyIdSecretRef: ""   # name of Secret with key: aws_access_key_id
    awsSecretAccessKeySecretRef: "" # name of Secret with key: aws_secret_access_key
  retention:
    days: 2555  # 7 years for compliance
    keep_daily: 30
    keep_weekly: 12
    keep_monthly: 12
    keep_yearly: 7
  postgresql:
    enabled: false
    schedule: "0 2 * * *" # daily at 02:00
    image: python:3.11-slim
    host: "postgres"
    port: 5432
    database: "llama_mapper"
    user: "postgres"
    passwordSecretRef: "" # name of Secret with key: PGPASSWORD
    resources:
      requests:
        cpu: "250m"
        memory: "512Mi"
      limits:
        cpu: "1"
        memory: "1Gi"
    nodeSelector: {}
    affinity: {}
    tolerations: []
  clickhouse:
    enabled: false
    schedule: "30 2 * * *" # daily at 02:30
    image: python:3.11-slim
    host: "clickhouse"
    port: 9000
    database: "mapper"
    user: "default"
    passwordSecretRef: "" # name of Secret with key: CLICKHOUSE_PASSWORD
    resources:
      requests:
        cpu: "250m"
        memory: "512Mi"
      limits:
        cpu: "1"
        memory: "1Gi"
    nodeSelector: {}
    affinity: {}
    tolerations: []
  redis:
    enabled: false
    schedule: "0 3 * * *" # daily at 03:00
    image: python:3.11-slim
    host: "redis"
    port: 6379
    passwordSecretRef: "" # name of Secret with key: REDIS_PASSWORD (optional)
    resources:
      requests:
        cpu: "100m"
        memory: "256Mi"
      limits:
        cpu: "500m"
        memory: "512Mi"
    nodeSelector: {}
    affinity: {}
    tolerations: []

restore:
  enabled: false
  # Choose one of: postgresql, clickhouse, or redis
  type: "postgresql"
  snapshot: "" # path under s3://<bucket>/<prefix>/... to restore
  image:
    postgresql: python:3.11-slim
    clickhouse: python:3.11-slim
    redis: python:3.11-slim
  postgresql:
    host: "postgres"
    port: 5432
    database: "llama_mapper"
    user: "postgres"
    passwordSecretRef: "" # name of Secret with key: PGPASSWORD
  clickhouse:
    host: "clickhouse"
    port: 9000
    database: "mapper"
    user: "default"
    passwordSecretRef: "" # name of Secret with key: CLICKHOUSE_PASSWORD
  redis:
    host: "redis"
    port: 6379
    passwordSecretRef: "" # name of Secret with key: REDIS_PASSWORD (optional)

# Azure-specific backup and restore configuration
azureBackups:
  enabled: false
  azure:
    subscriptionId: ""
    resourceGroup: "comply-ai-rg"
    keyVaultUrl: "https://comply-ai-keyvault.vault.azure.net/"
    region: "eastus"
    drRegion: "westus2"
    # Azure service principal credentials
    clientIdSecretRef: "" # name of Secret with key: client_id
    clientSecretSecretRef: "" # name of Secret with key: client_secret
    tenantIdSecretRef: "" # name of Secret with key: tenant_id
    subscriptionIdSecretRef: "" # name of Secret with key: subscription_id
  retention:
    days: 30  # Azure PostgreSQL default retention
    complianceDays: 2555  # 7 years for compliance
  postgresql:
    enabled: false
    schedule: "0 2 * * *"  # Daily at 2 AM
    image: python:3.11-slim
    serverName: "comply-ai-postgres"
    databaseName: "llama_mapper"
    adminUser: "complyaiadmin"
    resources:
      requests:
        cpu: "250m"
        memory: "512Mi"
      limits:
        cpu: "1"
        memory: "1Gi"
    nodeSelector: {}
    affinity: {}
    tolerations: []
  redis:
    enabled: false
    schedule: "0 3 * * *"  # Daily at 3 AM
    image: python:3.11-slim
    name: "comply-ai-redis"
    resources:
      requests:
        cpu: "100m"
        memory: "256Mi"
      limits:
        cpu: "500m"
        memory: "512Mi"
    nodeSelector: {}
    affinity: {}
    tolerations: []
  storage:
    accountName: "complyaistorage"
    containerName: "backups"
    sku: "Standard_GRS"
    immutableStorage: true
    versioning: true
    lifecycleManagement: true
  keyvault:
    enabled: false
    schedule: "0 4 * * *"  # Daily at 4 AM
    image: python:3.11-slim
    resources:
      requests:
        cpu: "100m"
        memory: "256Mi"
      limits:
        cpu: "500m"
        memory: "512Mi"
    nodeSelector: {}
    affinity: {}
    tolerations: []
  monitoring:
    enabled: false
    schedule: "0 6 * * *"  # Daily at 6 AM
    image: python:3.11-slim
    logAnalyticsWorkspace: "comply-ai-logs"
    actionGroup: "backup-alerts"
    resources:
      requests:
        cpu: "100m"
        memory: "256Mi"
      limits:
        cpu: "500m"
        memory: "512Mi"
    nodeSelector: {}
    affinity: {}
    tolerations: []

# Cost management and resource guardrails
costManagement:
  # Enable to create namespace-level ResourceQuota and LimitRange objects
  resourceQuota:
    enabled: false
    hard:
      # Set sensible defaults; tune per environment
      requests.cpu: "2"
      requests.memory: "4Gi"
      limits.cpu: "4"
      limits.memory: "8Gi"
      pods: "10"
      services: "5"
      configmaps: "20"
      persistentvolumeclaims: "0"
  limitRange:
    enabled: false
    defaultContainer:
      requests:
        cpu: "250m"
        memory: "512Mi"
      limits:
        cpu: "1"
        memory: "1Gi"

# Prometheus scraping via ServiceMonitor (Prometheus Operator)
serviceMonitor:
  enabled: true
  labels: {}
  interval: 15s
  scrapeTimeout: 5s

# Alerting rules (PrometheusRule via Prometheus Operator)
alerts:
  enabled: true
  labels: {}
  # Optional: set a URL to your repo docs for runbooks; used in alert annotations
  # Example: https://github.com/your-org/comply-ai/blob/main/docs/runbook/alert-runbooks.md
  runbookURL: ""
  thresholds:
    schemaValidMinPct: 99.5   # target >= 99.5%
    fallbackMaxPct: 10        # target < 10%
    latencyP95Seconds:
      tgi: 0.25               # 250ms on CPU/TGI
      vllm: 0.15              # 150ms on GPU/vLLM
    fiveXXErrorRatePct: 1     # critical if >= 1% over 5m
    # queueLagSeconds: 30     # Optional: enable if queue lag metric is available
  durations:
    short: 5m
    medium: 10m
    long: 15m

# Weekly evaluation scheduling and reporting
weeklyEvaluations:
  enabled: true
  schedule: "0 9 * * 1"  # Every Monday at 9 AM UTC
  redisUrl: ""  # Redis URL for scheduling (optional)
  databaseUrl: ""  # Database URL for persistence (optional)
  s3Bucket: ""  # S3 bucket for report storage (optional)
  awsRegion: "us-east-1"
  awsAccessKeyId:
    secretName: ""
    secretKey: "aws_access_key_id"
  awsSecretAccessKey:
    secretName: ""
    secretKey: "aws_secret_access_key"
  notificationEmail: ""  # Email for notifications (optional)
  slackWebhook:
    secretName: ""
    secretKey: "webhook_url"
  configMap: ""  # ConfigMap with weekly evaluation configuration (optional)
  goldenDataset: ""  # ConfigMap with golden dataset (optional)
  resources:
    requests:
      cpu: "250m"
      memory: "512Mi"
    limits:
      cpu: "1"
      memory: "1Gi"
  nodeSelector: {}
  affinity: {}
  tolerations: []