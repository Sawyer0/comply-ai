{"instruction": "Map the following detector output to the canonical taxonomy. Detector: deberta-toxicity, Output: toxic", "response": "{\"taxonomy\": [\"HARM.SPEECH.Toxicity\"], \"scores\": {\"HARM.SPEECH.Toxicity\": 0.8343458849948184}, \"confidence\": 0.8343458849948184, \"provenance\": {\"detector\": \"deberta-toxicity\", \"detector_version\": \"v1\"}}", "metadata": {"detector": "deberta-toxicity", "detector_label": "toxic", "canonical_label": "HARM.SPEECH.Toxicity", "example_type": "single_label", "template_index": 0}}
{"instruction": "Map detector result to canonical taxonomy: deberta-toxicity → toxic", "response": "{\"taxonomy\": [\"HARM.SPEECH.Toxicity\"], \"scores\": {\"HARM.SPEECH.Toxicity\": 0.8238104924669852}, \"confidence\": 0.8238104924669852, \"provenance\": {\"detector\": \"deberta-toxicity\", \"detector_version\": \"v1\"}}", "metadata": {"detector": "deberta-toxicity", "detector_label": "toxic", "canonical_label": "HARM.SPEECH.Toxicity", "example_type": "single_label", "template_index": 1}}
{"instruction": "Normalize to taxonomy: deberta-toxicity result = severe_toxic", "response": "{\"taxonomy\": [\"HARM.SPEECH.Toxicity\"], \"scores\": {\"HARM.SPEECH.Toxicity\": 0.7346730452877808}, \"confidence\": 0.7346730452877808, \"provenance\": {\"detector\": \"deberta-toxicity\", \"detector_version\": \"v1\"}}", "metadata": {"detector": "deberta-toxicity", "detector_label": "severe_toxic", "canonical_label": "HARM.SPEECH.Toxicity", "example_type": "single_label", "template_index": 0}}
{"instruction": "Convert this detector result to canonical format. Detector: deberta-toxicity, Result: severe_toxic", "response": "{\"taxonomy\": [\"HARM.SPEECH.Toxicity\"], \"scores\": {\"HARM.SPEECH.Toxicity\": 0.6788020619910552}, \"confidence\": 0.6788020619910552, \"provenance\": {\"detector\": \"deberta-toxicity\", \"detector_version\": \"v1\"}}", "metadata": {"detector": "deberta-toxicity", "detector_label": "severe_toxic", "canonical_label": "HARM.SPEECH.Toxicity", "example_type": "single_label", "template_index": 1}}
{"instruction": "Transform detector output to taxonomy format. Source: deberta-toxicity, Label: obscene", "response": "{\"taxonomy\": [\"HARM.SPEECH.Obscenity\"], \"scores\": {\"HARM.SPEECH.Obscenity\": 0.7336256828703961}, \"confidence\": 0.7336256828703961, \"provenance\": {\"detector\": \"deberta-toxicity\", \"detector_version\": \"v1\"}}", "metadata": {"detector": "deberta-toxicity", "detector_label": "obscene", "canonical_label": "HARM.SPEECH.Obscenity", "example_type": "single_label", "template_index": 0}}
{"instruction": "Normalize to taxonomy: deberta-toxicity result = obscene", "response": "{\"taxonomy\": [\"HARM.SPEECH.Obscenity\"], \"scores\": {\"HARM.SPEECH.Obscenity\": 0.7295483162592593}, \"confidence\": 0.7295483162592593, \"provenance\": {\"detector\": \"deberta-toxicity\", \"detector_version\": \"v1\"}}", "metadata": {"detector": "deberta-toxicity", "detector_label": "obscene", "canonical_label": "HARM.SPEECH.Obscenity", "example_type": "single_label", "template_index": 1}}
{"instruction": "Normalize to taxonomy: deberta-toxicity result = insult", "response": "{\"taxonomy\": [\"HARM.SPEECH.Insult\"], \"scores\": {\"HARM.SPEECH.Insult\": 0.8510489654346706}, \"confidence\": 0.8510489654346706, \"provenance\": {\"detector\": \"deberta-toxicity\", \"detector_version\": \"v1\"}}", "metadata": {"detector": "deberta-toxicity", "detector_label": "insult", "canonical_label": "HARM.SPEECH.Insult", "example_type": "single_label", "template_index": 0}}
{"instruction": "Standardize this detection: deberta-toxicity found 'insult'", "response": "{\"taxonomy\": [\"HARM.SPEECH.Insult\"], \"scores\": {\"HARM.SPEECH.Insult\": 0.8879314716181917}, \"confidence\": 0.8879314716181917, \"provenance\": {\"detector\": \"deberta-toxicity\", \"detector_version\": \"v1\"}}", "metadata": {"detector": "deberta-toxicity", "detector_label": "insult", "canonical_label": "HARM.SPEECH.Insult", "example_type": "single_label", "template_index": 1}}
{"instruction": "Map the following detector output to the canonical taxonomy. Detector: deberta-toxicity, Output: threat", "response": "{\"taxonomy\": [\"HARM.SPEECH.Threat\"], \"scores\": {\"HARM.SPEECH.Threat\": 0.9221715536682793}, \"confidence\": 0.9221715536682793, \"provenance\": {\"detector\": \"deberta-toxicity\", \"detector_version\": \"v1\"}}", "metadata": {"detector": "deberta-toxicity", "detector_label": "threat", "canonical_label": "HARM.SPEECH.Threat", "example_type": "single_label", "template_index": 0}}
{"instruction": "Normalize the detector output: deberta-toxicity detected 'threat'. Provide canonical mapping.", "response": "{\"taxonomy\": [\"HARM.SPEECH.Threat\"], \"scores\": {\"HARM.SPEECH.Threat\": 0.8863826658212558}, \"confidence\": 0.8863826658212558, \"provenance\": {\"detector\": \"deberta-toxicity\", \"detector_version\": \"v1\"}}", "metadata": {"detector": "deberta-toxicity", "detector_label": "threat", "canonical_label": "HARM.SPEECH.Threat", "example_type": "single_label", "template_index": 1}}
{"instruction": "Convert to canonical format: deberta-toxicity output 'identity_hate'", "response": "{\"taxonomy\": [\"HARM.SPEECH.Hate.Other\"], \"scores\": {\"HARM.SPEECH.Hate.Other\": 0.6981444592909601}, \"confidence\": 0.6981444592909601, \"provenance\": {\"detector\": \"deberta-toxicity\", \"detector_version\": \"v1\"}}", "metadata": {"detector": "deberta-toxicity", "detector_label": "identity_hate", "canonical_label": "HARM.SPEECH.Hate.Other", "example_type": "single_label", "template_index": 0}}
{"instruction": "Convert this detector result to canonical format. Detector: deberta-toxicity, Result: identity_hate", "response": "{\"taxonomy\": [\"HARM.SPEECH.Hate.Other\"], \"scores\": {\"HARM.SPEECH.Hate.Other\": 0.6985415126362917}, \"confidence\": 0.6985415126362917, \"provenance\": {\"detector\": \"deberta-toxicity\", \"detector_version\": \"v1\"}}", "metadata": {"detector": "deberta-toxicity", "detector_label": "identity_hate", "canonical_label": "HARM.SPEECH.Hate.Other", "example_type": "single_label", "template_index": 1}}
{"instruction": "Map to canonical labels: detoxify-hatebert detected 'toxic'", "response": "{\"taxonomy\": [\"HARM.SPEECH.Toxicity\"], \"scores\": {\"HARM.SPEECH.Toxicity\": 0.942586418914303}, \"confidence\": 0.942586418914303, \"provenance\": {\"detector\": \"detoxify-hatebert\", \"detector_version\": \"v1\"}}", "metadata": {"detector": "detoxify-hatebert", "detector_label": "toxic", "canonical_label": "HARM.SPEECH.Toxicity", "example_type": "single_label", "template_index": 0}}
{"instruction": "Map detector result to canonical taxonomy: detoxify-hatebert → toxic", "response": "{\"taxonomy\": [\"HARM.SPEECH.Toxicity\"], \"scores\": {\"HARM.SPEECH.Toxicity\": 0.9348467702562466}, \"confidence\": 0.9348467702562466, \"provenance\": {\"detector\": \"detoxify-hatebert\", \"detector_version\": \"v1\"}}", "metadata": {"detector": "detoxify-hatebert", "detector_label": "toxic", "canonical_label": "HARM.SPEECH.Toxicity", "example_type": "single_label", "template_index": 1}}
{"instruction": "Standardize this detection: detoxify-hatebert found 'obscene'", "response": "{\"taxonomy\": [\"HARM.SPEECH.Obscenity\"], \"scores\": {\"HARM.SPEECH.Obscenity\": 0.8392610859909978}, \"confidence\": 0.8392610859909978, \"provenance\": {\"detector\": \"detoxify-hatebert\", \"detector_version\": \"v1\"}}", "metadata": {"detector": "detoxify-hatebert", "detector_label": "obscene", "canonical_label": "HARM.SPEECH.Obscenity", "example_type": "single_label", "template_index": 0}}
{"instruction": "Convert this detector result to canonical format. Detector: detoxify-hatebert, Result: obscene", "response": "{\"taxonomy\": [\"HARM.SPEECH.Obscenity\"], \"scores\": {\"HARM.SPEECH.Obscenity\": 0.8669974892889746}, \"confidence\": 0.8669974892889746, \"provenance\": {\"detector\": \"detoxify-hatebert\", \"detector_version\": \"v1\"}}", "metadata": {"detector": "detoxify-hatebert", "detector_label": "obscene", "canonical_label": "HARM.SPEECH.Obscenity", "example_type": "single_label", "template_index": 1}}
{"instruction": "Convert to canonical format: detoxify-hatebert output 'threat'", "response": "{\"taxonomy\": [\"HARM.SPEECH.Threat\"], \"scores\": {\"HARM.SPEECH.Threat\": 0.8750871217125538}, \"confidence\": 0.8750871217125538, \"provenance\": {\"detector\": \"detoxify-hatebert\", \"detector_version\": \"v1\"}}", "metadata": {"detector": "detoxify-hatebert", "detector_label": "threat", "canonical_label": "HARM.SPEECH.Threat", "example_type": "single_label", "template_index": 0}}
{"instruction": "Transform detector output to taxonomy format. Source: detoxify-hatebert, Label: threat", "response": "{\"taxonomy\": [\"HARM.SPEECH.Threat\"], \"scores\": {\"HARM.SPEECH.Threat\": 0.8092123764566277}, \"confidence\": 0.8092123764566277, \"provenance\": {\"detector\": \"detoxify-hatebert\", \"detector_version\": \"v1\"}}", "metadata": {"detector": "detoxify-hatebert", "detector_label": "threat", "canonical_label": "HARM.SPEECH.Threat", "example_type": "single_label", "template_index": 1}}
{"instruction": "Map detector result to canonical taxonomy: detoxify-hatebert → insult", "response": "{\"taxonomy\": [\"HARM.SPEECH.Insult\"], \"scores\": {\"HARM.SPEECH.Insult\": 0.7925063410144013}, \"confidence\": 0.7925063410144013, \"provenance\": {\"detector\": \"detoxify-hatebert\", \"detector_version\": \"v1\"}}", "metadata": {"detector": "detoxify-hatebert", "detector_label": "insult", "canonical_label": "HARM.SPEECH.Insult", "example_type": "single_label", "template_index": 0}}
{"instruction": "Convert this detector result to canonical format. Detector: detoxify-hatebert, Result: insult", "response": "{\"taxonomy\": [\"HARM.SPEECH.Insult\"], \"scores\": {\"HARM.SPEECH.Insult\": 0.7936229355884136}, \"confidence\": 0.7936229355884136, \"provenance\": {\"detector\": \"detoxify-hatebert\", \"detector_version\": \"v1\"}}", "metadata": {"detector": "detoxify-hatebert", "detector_label": "insult", "canonical_label": "HARM.SPEECH.Insult", "example_type": "single_label", "template_index": 1}}
{"instruction": "Canonical mapping for: detoxify-hatebert detector output 'identity_attack'", "response": "{\"taxonomy\": [\"HARM.SPEECH.Hate.Other\"], \"scores\": {\"HARM.SPEECH.Hate.Other\": 0.7612969659754}, \"confidence\": 0.7612969659754, \"provenance\": {\"detector\": \"detoxify-hatebert\", \"detector_version\": \"v1\"}}", "metadata": {"detector": "detoxify-hatebert", "detector_label": "identity_attack", "canonical_label": "HARM.SPEECH.Hate.Other", "example_type": "single_label", "template_index": 0}}
{"instruction": "Convert to canonical format: detoxify-hatebert output 'identity_attack'", "response": "{\"taxonomy\": [\"HARM.SPEECH.Hate.Other\"], \"scores\": {\"HARM.SPEECH.Hate.Other\": 0.7805586262825437}, \"confidence\": 0.7805586262825437, \"provenance\": {\"detector\": \"detoxify-hatebert\", \"detector_version\": \"v1\"}}", "metadata": {"detector": "detoxify-hatebert", "detector_label": "identity_attack", "canonical_label": "HARM.SPEECH.Hate.Other", "example_type": "single_label", "template_index": 1}}
{"instruction": "Convert this detector result to canonical format. Detector: detoxify-hatebert, Result: sexual_explicit", "response": "{\"taxonomy\": [\"HARM.VIOLENCE.Sexual\"], \"scores\": {\"HARM.VIOLENCE.Sexual\": 0.8709577812973941}, \"confidence\": 0.8709577812973941, \"provenance\": {\"detector\": \"detoxify-hatebert\", \"detector_version\": \"v1\"}}", "metadata": {"detector": "detoxify-hatebert", "detector_label": "sexual_explicit", "canonical_label": "HARM.VIOLENCE.Sexual", "example_type": "single_label", "template_index": 0}}
{"instruction": "Normalize the detector output: detoxify-hatebert detected 'sexual_explicit'. Provide canonical mapping.", "response": "{\"taxonomy\": [\"HARM.VIOLENCE.Sexual\"], \"scores\": {\"HARM.VIOLENCE.Sexual\": 0.8420248861095658}, \"confidence\": 0.8420248861095658, \"provenance\": {\"detector\": \"detoxify-hatebert\", \"detector_version\": \"v1\"}}", "metadata": {"detector": "detoxify-hatebert", "detector_label": "sexual_explicit", "canonical_label": "HARM.VIOLENCE.Sexual", "example_type": "single_label", "template_index": 1}}
{"instruction": "Map detector result to canonical taxonomy: llama-guard → violence", "response": "{\"taxonomy\": [\"HARM.VIOLENCE.Physical\"], \"scores\": {\"HARM.VIOLENCE.Physical\": 0.7875265703598058}, \"confidence\": 0.7875265703598058, \"provenance\": {\"detector\": \"llama-guard\", \"detector_version\": \"v1\"}}", "metadata": {"detector": "llama-guard", "detector_label": "violence", "canonical_label": "HARM.VIOLENCE.Physical", "example_type": "single_label", "template_index": 0}}
{"instruction": "Normalize to taxonomy: llama-guard result = violence", "response": "{\"taxonomy\": [\"HARM.VIOLENCE.Physical\"], \"scores\": {\"HARM.VIOLENCE.Physical\": 0.7979933264043111}, \"confidence\": 0.7979933264043111, \"provenance\": {\"detector\": \"llama-guard\", \"detector_version\": \"v1\"}}", "metadata": {"detector": "llama-guard", "detector_label": "violence", "canonical_label": "HARM.VIOLENCE.Physical", "example_type": "single_label", "template_index": 1}}
{"instruction": "Map the following detector output to the canonical taxonomy. Detector: llama-guard, Output: self-harm", "response": "{\"taxonomy\": [\"HARM.VIOLENCE.SelfHarm\"], \"scores\": {\"HARM.VIOLENCE.SelfHarm\": 0.9242586537987738}, \"confidence\": 0.9242586537987738, \"provenance\": {\"detector\": \"llama-guard\", \"detector_version\": \"v1\"}}", "metadata": {"detector": "llama-guard", "detector_label": "self-harm", "canonical_label": "HARM.VIOLENCE.SelfHarm", "example_type": "single_label", "template_index": 0}}
{"instruction": "Transform detector output to taxonomy format. Source: llama-guard, Label: self-harm", "response": "{\"taxonomy\": [\"HARM.VIOLENCE.SelfHarm\"], \"scores\": {\"HARM.VIOLENCE.SelfHarm\": 0.9225829744752144}, \"confidence\": 0.9225829744752144, \"provenance\": {\"detector\": \"llama-guard\", \"detector_version\": \"v1\"}}", "metadata": {"detector": "llama-guard", "detector_label": "self-harm", "canonical_label": "HARM.VIOLENCE.SelfHarm", "example_type": "single_label", "template_index": 1}}
{"instruction": "Convert this detector result to canonical format. Detector: llama-guard, Result: sexual", "response": "{\"taxonomy\": [\"HARM.VIOLENCE.Sexual\"], \"scores\": {\"HARM.VIOLENCE.Sexual\": 0.8416048091741366}, \"confidence\": 0.8416048091741366, \"provenance\": {\"detector\": \"llama-guard\", \"detector_version\": \"v1\"}}", "metadata": {"detector": "llama-guard", "detector_label": "sexual", "canonical_label": "HARM.VIOLENCE.Sexual", "example_type": "single_label", "template_index": 0}}
{"instruction": "Transform detector output to taxonomy format. Source: llama-guard, Label: sexual", "response": "{\"taxonomy\": [\"HARM.VIOLENCE.Sexual\"], \"scores\": {\"HARM.VIOLENCE.Sexual\": 0.8070092019034324}, \"confidence\": 0.8070092019034324, \"provenance\": {\"detector\": \"llama-guard\", \"detector_version\": \"v1\"}}", "metadata": {"detector": "llama-guard", "detector_label": "sexual", "canonical_label": "HARM.VIOLENCE.Sexual", "example_type": "single_label", "template_index": 1}}
{"instruction": "Transform detector output to taxonomy format. Source: llama-guard, Label: sexual/minors", "response": "{\"taxonomy\": [\"HARM.VIOLENCE.ChildSexualAbuse\"], \"scores\": {\"HARM.VIOLENCE.ChildSexualAbuse\": 0.8690417577858104}, \"confidence\": 0.8690417577858104, \"provenance\": {\"detector\": \"llama-guard\", \"detector_version\": \"v1\"}}", "metadata": {"detector": "llama-guard", "detector_label": "sexual/minors", "canonical_label": "HARM.VIOLENCE.ChildSexualAbuse", "example_type": "single_label", "template_index": 0}}
{"instruction": "Canonical mapping for: llama-guard detector output 'sexual/minors'", "response": "{\"taxonomy\": [\"HARM.VIOLENCE.ChildSexualAbuse\"], \"scores\": {\"HARM.VIOLENCE.ChildSexualAbuse\": 0.9209333266537983}, \"confidence\": 0.9209333266537983, \"provenance\": {\"detector\": \"llama-guard\", \"detector_version\": \"v1\"}}", "metadata": {"detector": "llama-guard", "detector_label": "sexual/minors", "canonical_label": "HARM.VIOLENCE.ChildSexualAbuse", "example_type": "single_label", "template_index": 1}}
{"instruction": "Map detector result to canonical taxonomy: llama-guard → hate", "response": "{\"taxonomy\": [\"HARM.SPEECH.Hate.Other\"], \"scores\": {\"HARM.SPEECH.Hate.Other\": 0.7893757139162481}, \"confidence\": 0.7893757139162481, \"provenance\": {\"detector\": \"llama-guard\", \"detector_version\": \"v1\"}}", "metadata": {"detector": "llama-guard", "detector_label": "hate", "canonical_label": "HARM.SPEECH.Hate.Other", "example_type": "single_label", "template_index": 0}}
{"instruction": "Normalize the detector output: llama-guard detected 'hate'. Provide canonical mapping.", "response": "{\"taxonomy\": [\"HARM.SPEECH.Hate.Other\"], \"scores\": {\"HARM.SPEECH.Hate.Other\": 0.8208497765631648}, \"confidence\": 0.8208497765631648, \"provenance\": {\"detector\": \"llama-guard\", \"detector_version\": \"v1\"}}", "metadata": {"detector": "llama-guard", "detector_label": "hate", "canonical_label": "HARM.SPEECH.Hate.Other", "example_type": "single_label", "template_index": 1}}
{"instruction": "Map to canonical labels: llama-guard detected 'harassment'", "response": "{\"taxonomy\": [\"HARM.SPEECH.Insult\"], \"scores\": {\"HARM.SPEECH.Insult\": 0.8054676904909814}, \"confidence\": 0.8054676904909814, \"provenance\": {\"detector\": \"llama-guard\", \"detector_version\": \"v1\"}}", "metadata": {"detector": "llama-guard", "detector_label": "harassment", "canonical_label": "HARM.SPEECH.Insult", "example_type": "single_label", "template_index": 0}}
{"instruction": "Standardize this detection: llama-guard found 'harassment'", "response": "{\"taxonomy\": [\"HARM.SPEECH.Insult\"], \"scores\": {\"HARM.SPEECH.Insult\": 0.7556254526447735}, \"confidence\": 0.7556254526447735, \"provenance\": {\"detector\": \"llama-guard\", \"detector_version\": \"v1\"}}", "metadata": {"detector": "llama-guard", "detector_label": "harassment", "canonical_label": "HARM.SPEECH.Insult", "example_type": "single_label", "template_index": 1}}
{"instruction": "Normalize the detector output: llama-guard detected 'threats'. Provide canonical mapping.", "response": "{\"taxonomy\": [\"HARM.SPEECH.Threat\"], \"scores\": {\"HARM.SPEECH.Threat\": 0.754181773278284}, \"confidence\": 0.754181773278284, \"provenance\": {\"detector\": \"llama-guard\", \"detector_version\": \"v1\"}}", "metadata": {"detector": "llama-guard", "detector_label": "threats", "canonical_label": "HARM.SPEECH.Threat", "example_type": "single_label", "template_index": 0}}
{"instruction": "Normalize to taxonomy: llama-guard result = threats", "response": "{\"taxonomy\": [\"HARM.SPEECH.Threat\"], \"scores\": {\"HARM.SPEECH.Threat\": 0.7804084055426946}, \"confidence\": 0.7804084055426946, \"provenance\": {\"detector\": \"llama-guard\", \"detector_version\": \"v1\"}}", "metadata": {"detector": "llama-guard", "detector_label": "threats", "canonical_label": "HARM.SPEECH.Threat", "example_type": "single_label", "template_index": 1}}
{"instruction": "Normalize the detector output: llama-guard detected 'pii'. Provide canonical mapping.", "response": "{\"taxonomy\": [\"PII.Other\"], \"scores\": {\"PII.Other\": 0.9444836638529628}, \"confidence\": 0.9444836638529628, \"provenance\": {\"detector\": \"llama-guard\", \"detector_version\": \"v1\"}}", "metadata": {"detector": "llama-guard", "detector_label": "pii", "canonical_label": "PII.Other", "example_type": "single_label", "template_index": 0}}
{"instruction": "Map to canonical labels: llama-guard detected 'pii'", "response": "{\"taxonomy\": [\"PII.Other\"], \"scores\": {\"PII.Other\": 0.9074917240966348}, \"confidence\": 0.9074917240966348, \"provenance\": {\"detector\": \"llama-guard\", \"detector_version\": \"v1\"}}", "metadata": {"detector": "llama-guard", "detector_label": "pii", "canonical_label": "PII.Other", "example_type": "single_label", "template_index": 1}}
{"instruction": "Standardize this detection: llama-guard found 'jailbreak'", "response": "{\"taxonomy\": [\"JAILBREAK.Attempt\"], \"scores\": {\"JAILBREAK.Attempt\": 0.7187933610479029}, \"confidence\": 0.7187933610479029, \"provenance\": {\"detector\": \"llama-guard\", \"detector_version\": \"v1\"}}", "metadata": {"detector": "llama-guard", "detector_label": "jailbreak", "canonical_label": "JAILBREAK.Attempt", "example_type": "single_label", "template_index": 0}}
{"instruction": "Canonical mapping for: llama-guard detector output 'jailbreak'", "response": "{\"taxonomy\": [\"JAILBREAK.Attempt\"], \"scores\": {\"JAILBREAK.Attempt\": 0.7629897642993511}, \"confidence\": 0.7629897642993511, \"provenance\": {\"detector\": \"llama-guard\", \"detector_version\": \"v1\"}}", "metadata": {"detector": "llama-guard", "detector_label": "jailbreak", "canonical_label": "JAILBREAK.Attempt", "example_type": "single_label", "template_index": 1}}
{"instruction": "Map the following detector output to the canonical taxonomy. Detector: llama-guard, Output: prompt_injection", "response": "{\"taxonomy\": [\"PROMPT_INJECTION.Other\"], \"scores\": {\"PROMPT_INJECTION.Other\": 0.933365962461282}, \"confidence\": 0.933365962461282, \"provenance\": {\"detector\": \"llama-guard\", \"detector_version\": \"v1\"}}", "metadata": {"detector": "llama-guard", "detector_label": "prompt_injection", "canonical_label": "PROMPT_INJECTION.Other", "example_type": "single_label", "template_index": 0}}
{"instruction": "Convert this detector result to canonical format. Detector: llama-guard, Result: prompt_injection", "response": "{\"taxonomy\": [\"PROMPT_INJECTION.Other\"], \"scores\": {\"PROMPT_INJECTION.Other\": 0.918891958599504}, \"confidence\": 0.918891958599504, \"provenance\": {\"detector\": \"llama-guard\", \"detector_version\": \"v1\"}}", "metadata": {"detector": "llama-guard", "detector_label": "prompt_injection", "canonical_label": "PROMPT_INJECTION.Other", "example_type": "single_label", "template_index": 1}}
{"instruction": "Convert to canonical format: openai-moderation output 'hate'", "response": "{\"taxonomy\": [\"HARM.SPEECH.Hate.Other\"], \"scores\": {\"HARM.SPEECH.Hate.Other\": 0.7460563103528783}, \"confidence\": 0.7460563103528783, \"provenance\": {\"detector\": \"openai-moderation\", \"detector_version\": \"v1\"}}", "metadata": {"detector": "openai-moderation", "detector_label": "hate", "canonical_label": "HARM.SPEECH.Hate.Other", "example_type": "single_label", "template_index": 0}}
{"instruction": "Convert this detector result to canonical format. Detector: openai-moderation, Result: hate", "response": "{\"taxonomy\": [\"HARM.SPEECH.Hate.Other\"], \"scores\": {\"HARM.SPEECH.Hate.Other\": 0.7325220729226026}, \"confidence\": 0.7325220729226026, \"provenance\": {\"detector\": \"openai-moderation\", \"detector_version\": \"v1\"}}", "metadata": {"detector": "openai-moderation", "detector_label": "hate", "canonical_label": "HARM.SPEECH.Hate.Other", "example_type": "single_label", "template_index": 1}}
{"instruction": "Map detector result to canonical taxonomy: openai-moderation → hate/threatening", "response": "{\"taxonomy\": [\"HARM.SPEECH.Hate.Other\"], \"scores\": {\"HARM.SPEECH.Hate.Other\": 0.7270075489306388}, \"confidence\": 0.7270075489306388, \"provenance\": {\"detector\": \"openai-moderation\", \"detector_version\": \"v1\"}}", "metadata": {"detector": "openai-moderation", "detector_label": "hate/threatening", "canonical_label": "HARM.SPEECH.Hate.Other", "example_type": "single_label", "template_index": 0}}
{"instruction": "Normalize to taxonomy: openai-moderation result = hate/threatening", "response": "{\"taxonomy\": [\"HARM.SPEECH.Hate.Other\"], \"scores\": {\"HARM.SPEECH.Hate.Other\": 0.7015794964858648}, \"confidence\": 0.7015794964858648, \"provenance\": {\"detector\": \"openai-moderation\", \"detector_version\": \"v1\"}}", "metadata": {"detector": "openai-moderation", "detector_label": "hate/threatening", "canonical_label": "HARM.SPEECH.Hate.Other", "example_type": "single_label", "template_index": 1}}
{"instruction": "Map detector result to canonical taxonomy: openai-moderation → self-harm", "response": "{\"taxonomy\": [\"HARM.VIOLENCE.SelfHarm\"], \"scores\": {\"HARM.VIOLENCE.SelfHarm\": 0.7374997268432434}, \"confidence\": 0.7374997268432434, \"provenance\": {\"detector\": \"openai-moderation\", \"detector_version\": \"v1\"}}", "metadata": {"detector": "openai-moderation", "detector_label": "self-harm", "canonical_label": "HARM.VIOLENCE.SelfHarm", "example_type": "single_label", "template_index": 0}}
{"instruction": "Normalize to taxonomy: openai-moderation result = self-harm", "response": "{\"taxonomy\": [\"HARM.VIOLENCE.SelfHarm\"], \"scores\": {\"HARM.VIOLENCE.SelfHarm\": 0.6918866325543896}, \"confidence\": 0.6918866325543896, \"provenance\": {\"detector\": \"openai-moderation\", \"detector_version\": \"v1\"}}", "metadata": {"detector": "openai-moderation", "detector_label": "self-harm", "canonical_label": "HARM.VIOLENCE.SelfHarm", "example_type": "single_label", "template_index": 1}}
