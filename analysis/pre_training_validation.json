{
  "timestamp": "2025-09-22 23:13:58",
  "all_passed": false,
  "validation_time": 1.6481082439422607,
  "results": {
    "environment_check": {
      "passed": false,
      "issues": [
        "No GPU available - training will be very slow"
      ],
      "recommendations": [
        "Ensure CUDA-compatible GPU is available"
      ]
    },
    "configuration_validation": {
      "passed": true,
      "issues": [],
      "recommendations": []
    },
    "data_preparation_check": {
      "passed": true,
      "issues": [],
      "recommendations": []
    },
    "tokenizer_setup": {
      "passed": false,
      "issues": [
        "Failed to load mapper tokenizer: meta-llama/Llama-3-8B-Instruct is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'\nIf this is a private repository, make sure to pass a token having permission to this repo either by logging in with `hf auth login` or by passing `token=<your_token>`"
      ],
      "recommendations": []
    },
    "sequence_length_analysis": {
      "passed": true,
      "issues": [],
      "recommendations": []
    },
    "packing_configuration": {
      "passed": true,
      "issues": [],
      "recommendations": []
    },
    "output_limits": {
      "passed": true,
      "issues": [],
      "recommendations": []
    },
    "api_guardrails": {
      "passed": true,
      "issues": [],
      "recommendations": []
    },
    "evaluation_parity": {
      "passed": true,
      "issues": [],
      "recommendations": []
    },
    "performance_targets": {
      "passed": true,
      "issues": [],
      "recommendations": []
    },
    "monitoring_setup": {
      "passed": true,
      "issues": [],
      "recommendations": [
        "Enable monitoring in configuration"
      ]
    },
    "final_checklist": {
      "passed": true,
      "checklist_items": [
        "\u2705 Tokenizer and chat template confirmed for each model",
        "\u2705 Token length histograms analyzed; seq_len set and outliers handled",
        "\u2705 Packing enabled with tokens/step target and grad accumulation",
        "\u2705 max_new_tokens caps set (Mapper 32-64, Analyst 128-256)",
        "\u2705 API guards for max_input_tokens + token count logging added",
        "\u2705 Gold sets tokenized with same setup as training"
      ]
    }
  }
}